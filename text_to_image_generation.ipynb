{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-to-Image Generation with a Pretrained Diffusion Model\n",
    "\n",
    "Этот ноутбук показывает, как собрать простой пайплайн текст-в-изображение с использованием предобученной диффузионной модели. Структура следует типичному рабочему процессу: сначала объясняем основные блоки, затем демонстрируем отдельные шаги (токенизация текста, работа шумового расписания), и завершаем генерацией изображения по заданному описанию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка окружения и зависимостей\n",
    "\n",
    "В диффузионных моделях нам нужны библиотеки `diffusers`, `transformers` и `torch`. Этот блок ставит зависимости и настраивает устройство выполнения (CPU/GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка зависимостей (раскомментируйте при первом запуске)\n",
    "# !pip install -q diffusers transformers accelerate torch torchvision matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Импорты и выбор вычислительного устройства\n",
    "\n",
    "Здесь подключаем необходимые модули, а также определяем, есть ли доступная GPU для ускорения инференса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Определяем устройство: если есть CUDA, используем её для ускорения\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DTYPE = torch.float16 if DEVICE == 'cuda' else torch.float32\n",
    "\n",
    "print(f'Using device: {DEVICE}, dtype: {DTYPE}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Загрузка предобученной модели\n",
    "\n",
    "Мы используем компактную модель [`stabilityai/sdxl-turbo`](https://huggingface.co/stabilityai/sdxl-turbo), оптимизированную для быстрого инференса. Здесь создаём пайплайн и переносим его на выбранное устройство."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'stabilityai/sdxl-turbo'\n",
    "variant = 'fp16' if DTYPE == torch.float16 else None\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=DTYPE,\n",
    "    variant=variant,\n",
    ")\n",
    "pipe = pipe.to(DEVICE)\n",
    "\n",
    "# Для воспроизводимости задаём сид\n",
    "generator = torch.Generator(device=DEVICE).manual_seed(42)\n",
    "print('Pipeline is ready')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Блок токенизации текста\n",
    "\n",
    "Диффузионная модель принимает векторное представление текста. Этот блок показывает, как токенизатор превращает строку в тензоры, пригодные для подачи в текстовый энкодер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_prompt(prompt: str):\n",
    "    '''Возвращает токенизированный запрос и сопутствующие тензоры.'''\n",
    "    tokenized = pipe.tokenizer(\n",
    "        prompt,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=pipe.tokenizer.model_max_length,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "    return tokenized\n",
    "\n",
    "sample_prompt = 'a serene watercolor landscape of mountains at sunrise'\n",
    "encoded = tokenize_prompt(sample_prompt)\n",
    "print('Input IDs shape:', encoded.input_ids.shape)\n",
    "print('Attention mask shape:', encoded.attention_mask.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Шумовое расписание и денойзинг (обзор)\n",
    "\n",
    "Диффузионные модели постепенно удаляют шум из латентного представления. В этом блоке мы смотрим на расписание шагов и иллюстрируем добавление шума на одном из таймстепов. Это помогает понять, как работает прямой процесс (добавление шума), тогда как обратный процесс (денойзинг) выполняется моделью автоматически."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем список таймстепов из шедулера\n",
    "scheduler = pipe.scheduler\n",
    "print('Number of timesteps:', len(scheduler.timesteps))\n",
    "\n",
    "# Демонстрация добавления шума к случайным латентам\n",
    "latent_shape = (1, pipe.unet.config.in_channels, pipe.unet.config.sample_size, pipe.unet.config.sample_size)\n",
    "base_latents = torch.randn(latent_shape)\n",
    "noise = torch.randn_like(base_latents)\n",
    "step_index = len(scheduler.timesteps) // 2\n",
    "noisy_latents = scheduler.add_noise(base_latents, noise, scheduler.timesteps[step_index])\n",
    "\n",
    "# Для наглядности покажем распределение значений до и после добавления шума\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "axes[0].hist(base_latents.flatten().numpy(), bins=40, color='steelblue')\n",
    "axes[0].set_title('Базовые латенты')\n",
    "axes[1].hist(noisy_latents.flatten().numpy(), bins=40, color='darkorange')\n",
    "axes[1].set_title('Зашумлённые латенты')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Генерация изображения по текстовому описанию\n",
    "\n",
    "Теперь запускаем полный пайплайн: передаём запрос, выполняем несколько итераций денойзинга и визуализируем результат. Модель `sdxl-turbo` хорошо работает с 4 шагами и нулевой классификационной свободой (`guidance_scale=0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = 'a cozy cottage beside a lake under a starry night sky, watercolor illustration'\n",
    "\n",
    "image = pipe(\n",
    "    final_prompt,\n",
    "    num_inference_steps=4,\n",
    "    guidance_scale=0.0,\n",
    "    generator=generator,\n",
    ").images[0]\n",
    "\n",
    "# Сохраняем и показываем результат\n",
    "output_path = 'generated_sample.png'\n",
    "image.save(output_path)\n",
    "print(f'Saved image to {output_path}')\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.title(final_prompt)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Итоги\n",
    "\n",
    "Мы прошли через ключевые этапы текст-ту-изображение диффузионного пайплайна: разобрались, зачем нужен каждый блок, посмотрели на токенизацию и шумовое расписание, а затем сгенерировали финальное изображение с помощью предобученной модели. Чтобы адаптировать ноутбук под свои задачи, измените текстовый запрос или выберите другую модель в `model_id`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}